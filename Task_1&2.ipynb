{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Dataset Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing:\n",
    "- Use visualizations (histograms, scatter plots, bar graphs, etc.) to understand the\n",
    "distribution of features and identify any potential patterns/dependencies or\n",
    "outliers.\n",
    "- Identify the data types of each feature (numeric, categorical, text, etc.). For\n",
    "numeric data, show its characteristics like mean, median, standard deviation, etc.\n",
    "- Identify and handle missing values (null values) in the data. This could involve\n",
    "removing rows with missing values, fixing missing values with appropriate\n",
    "strategies, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading  Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"HCV-Egy-Data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(figsize=(40,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(28, 28))  # Adjust the width and height as needed\n",
    "\n",
    "sns.heatmap(df.corr(), cmap='Reds', annot=True, fmt='.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 29\n",
    "fig, axes = plt.subplots(nrows=num_features, ncols=1, figsize=(10, 5 * num_features))\n",
    "\n",
    "# Loop through each feature to create a PDF plot\n",
    "for i, column in enumerate(df):\n",
    "    # Plotting the density\n",
    "    df[column].plot(kind='density', ax=axes[i], color='blue', alpha=0.5, label='PDF')\n",
    "\n",
    "    # Calculate mean, median, and mode\n",
    "    mean = df[column].mean()\n",
    "    median = df[column].median()\n",
    "    mode = df[column].mode()[0]\n",
    "\n",
    "    # Marking mean, median, and mode with horizontal lines\n",
    "    axes[i].axvline(x=mean , color='red', linestyle='--', label=f'Mean: {mean:.2f}')  # Adjusted y-value for visibility\n",
    "    axes[i].axvline(x=median, color='green', linestyle='--', label=f'Median: {median:.2f}')  # Adjusted y-value for visibility\n",
    "    axes[i].axvline(x=mode , color='purple', linestyle='--', label=f'Mode: {mode:.2f}')  # Adjusted y-value for visibility\n",
    "\n",
    "    # Adding titles and labels\n",
    "    axes[i].set_title(f'Probability Density Function for {column}')\n",
    "    axes[i].set_xlabel(column)\n",
    "    axes[i].set_ylabel('Density')\n",
    "    axes[i].legend()\n",
    "    axes[i].grid()\n",
    "\n",
    "# Adjust layout and show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind='box', subplots=True, sharex=False, sharey=False, layout=(10,3), figsize=(15,25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = np.percentile(df['ALT after 24 w'], 25)\n",
    "Q3 = np.percentile(df['ALT after 24 w'], 75)\n",
    "IQR = Q3 - Q1\n",
    "df = df[(df['ALT after 24 w'] >= Q1 - 1.5 * IQR) & (df['ALT after 24 w'] <= Q3 + 1.5 * IQR)]\n",
    "\n",
    "Q1 = np.percentile(df['RNA 12'], 25)\n",
    "Q3 = np.percentile(df['RNA 12'], 75)\n",
    "IQR = Q3 - Q1\n",
    "df = df[(df['RNA 12'] >= Q1 - 1.5 * IQR) & (df['RNA 12'] <= Q3 + 1.5 * IQR)]\n",
    "\n",
    "df.plot(kind='box', subplots=True, sharex=False, sharey=False, layout=(10,3), figsize=(15,25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Update NN weights using Perceptron Rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_data = df.sample(frac=1)\n",
    "\n",
    "X = df.iloc[:,:-1].values\n",
    "Y = df.iloc[:,-1].values\n",
    "\n",
    "X_train, m_test, Y_train, my_test = train_test_split(X, Y, test_size = 0.30, random_state = 0)\n",
    "\n",
    "X_validate, X_test, Y_validate, Y_test = train_test_split(m_test, my_test, test_size = 1/3, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "  return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def targetToVector(target):\n",
    "  return [1 if i+1 == target else 0 for i in range(4)]\n",
    "\n",
    "def fitness(predictedVector, targetVector):\n",
    "    return sum([abs(targetVector[i] - predictedVector[i]) for i in range(len(predictedVector))])\n",
    "\n",
    "def randomPopulation(size=500):\n",
    "   W1s = [[[random.randint(-10, 10) for i in range(28)] for j in range(10)] for count in range(size)]\n",
    "   W2s = [[[random.randint(-10, 10) for i in range(10)] for j in range(4)] for count in range(size)]\n",
    "   B1s = [[random.randint(-5, 5) for i in range(10)] for count in range(size)]\n",
    "   B2s = [[random.randint(-5, 5) for i in range(4)] for count in range(size)]\n",
    "   return (W1s, B1s) , (W2s, B2s)\n",
    "\n",
    "def crossover(rate, population):\n",
    "    tmp_pop = population.copy()\n",
    "    crossed_pop = []\n",
    "    def cross(g1, g2):\n",
    "        cp = random.randrange(0, len(population[0]))\n",
    "        tg1_1 = g1[:cp]\n",
    "        tg1_2 = g1[cp:]\n",
    "        tg2_1 = g2[:cp]\n",
    "        tg2_2 = g2[cp:]\n",
    "        return (tg1_1 + tg2_2, tg2_1 + tg1_2)\n",
    "    for i in range(int(rate*len(population))):\n",
    "        p1 = tmp_pop[random.randrange(0, len(tmp_pop))]\n",
    "        tmp_pop.remove(p1)\n",
    "        p2 = tmp_pop[random.randrange(0, len(tmp_pop))]\n",
    "        tmp_pop.remove(p2)\n",
    "        c1, c2 = cross(p1, p2)\n",
    "        crossed_pop.extend([c1, c2])\n",
    "    return crossed_pop + tmp_pop\n",
    "\n",
    "def mutationWeights(rate, weightCount, population):\n",
    "   newPop = population.copy()\n",
    "   limit = rate*(len(population))\n",
    "   for i, gene in enumerate(population):\n",
    "      if (random() <= rate):\n",
    "         if (limit > 0):\n",
    "            limit -=1\n",
    "            for j in range(weightCount):\n",
    "              idx = random.randrange(0, len(gene))\n",
    "              gene[idx] = random.randint(-10, 10)\n",
    "              newPop[i] = gene\n",
    "         else:\n",
    "            break \n",
    "         \n",
    "   return newPop\n",
    "\n",
    "def mutationBias(rate,  population):\n",
    "   newPop = population.copy()\n",
    "   limit = rate*(len(population))\n",
    "   for i, gene in enumerate(population):\n",
    "      if (random() <= rate):\n",
    "         if (limit > 0):\n",
    "            limit -=1\n",
    "            gene = random.randint(-5, 5)\n",
    "            newPop[i] = gene\n",
    "         else:\n",
    "            break \n",
    "         \n",
    "   return newPop\n",
    "   \n",
    "def selection(rate, population, fitness):\n",
    "   selected = list(map(lambda y: y[0], sorted([(population[i], fitness[i]) for i in range(len(population))], key = lambda x: x[1])[:int(rate*len(population))]))\n",
    "   return selected.extend(selected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = [[random.randint(-10, 10) for i in range(28)] for j in range(10)]\n",
    "W2 = [[random.randint(-10, 10) for i in range(10)] for j in range(4)] # to be changed\n",
    "B1 = [random.randint(-5, 5) for i in range(10)]\n",
    "B2 = [random.randint(-5, 5) for i in range(4)]\n",
    "\n",
    "\n",
    "sigs = np.vectorize(sigmoid)\n",
    "\n",
    "exitCondition = False\n",
    "counter = 0\n",
    "while (counter < 2000):\n",
    "    counter += 1\n",
    "    np.random.shuffle(X_train)\n",
    "    batches = [[X_train[bf * 69 + i] for i in range(69) ] for bf in range(14)]\n",
    "\n",
    "    number_of_batches = len(batches)\n",
    "\n",
    "    for batch in batches:\n",
    "        results = []\n",
    "\n",
    "        for dataPoint in batch:\n",
    "           midResult = np.dot(W1, dataPoint)\n",
    "           actv_midResult = sigs(midResult + B1)\n",
    "\n",
    "           finalResult = np.dot(W2, actv_midResult)\n",
    "           actv_finalResult = sigs(finalResult + B2)\n",
    "           print(actv_finalResult)\n",
    "           results.append(actv_finalResult)\n",
    "\n",
    "           \n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "\n",
    "        # code for updating weights and biases\n",
    "\n",
    "    # code for validation\n",
    " \n",
    " # code for testing\n",
    "\n",
    "\n",
    "           \n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
