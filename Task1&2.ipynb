{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Dataset Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing:\n",
    "- Use visualizations (histograms, scatter plots, bar graphs, etc.) to understand the\n",
    "distribution of features and identify any potential patterns/dependencies or\n",
    "outliers.\n",
    "- Identify the data types of each feature (numeric, categorical, text, etc.). For\n",
    "numeric data, show its characteristics like mean, median, standard deviation, etc.\n",
    "- Identify and handle missing values (null values) in the data. This could involve\n",
    "removing rows with missing values, fixing missing values with appropriate\n",
    "strategies, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading  Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Fever</th>\n",
       "      <th>Nausea/Vomting</th>\n",
       "      <th>Headache</th>\n",
       "      <th>Diarrhea</th>\n",
       "      <th>Fatigue &amp; generalized bone ache</th>\n",
       "      <th>Jaundice</th>\n",
       "      <th>Epigastric pain</th>\n",
       "      <th>...</th>\n",
       "      <th>ALT 36</th>\n",
       "      <th>ALT 48</th>\n",
       "      <th>ALT after 24 w</th>\n",
       "      <th>RNA Base</th>\n",
       "      <th>RNA 4</th>\n",
       "      <th>RNA 12</th>\n",
       "      <th>RNA EOT</th>\n",
       "      <th>RNA EF</th>\n",
       "      <th>Baseline histological Grading</th>\n",
       "      <th>Baselinehistological staging</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>655330</td>\n",
       "      <td>634536</td>\n",
       "      <td>288194</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>123</td>\n",
       "      <td>44</td>\n",
       "      <td>40620</td>\n",
       "      <td>538635</td>\n",
       "      <td>637056</td>\n",
       "      <td>336804</td>\n",
       "      <td>31085</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>571148</td>\n",
       "      <td>661346</td>\n",
       "      <td>5</td>\n",
       "      <td>735945</td>\n",
       "      <td>558829</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>48</td>\n",
       "      <td>77</td>\n",
       "      <td>33</td>\n",
       "      <td>1041941</td>\n",
       "      <td>449939</td>\n",
       "      <td>585688</td>\n",
       "      <td>744463</td>\n",
       "      <td>582301</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>94</td>\n",
       "      <td>90</td>\n",
       "      <td>30</td>\n",
       "      <td>660410</td>\n",
       "      <td>738756</td>\n",
       "      <td>3731527</td>\n",
       "      <td>338946</td>\n",
       "      <td>242861</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1380</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>63</td>\n",
       "      <td>44</td>\n",
       "      <td>45</td>\n",
       "      <td>387795</td>\n",
       "      <td>55938</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1381</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>97</td>\n",
       "      <td>64</td>\n",
       "      <td>41</td>\n",
       "      <td>481378</td>\n",
       "      <td>152961</td>\n",
       "      <td>393339</td>\n",
       "      <td>73574</td>\n",
       "      <td>236273</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>87</td>\n",
       "      <td>39</td>\n",
       "      <td>24</td>\n",
       "      <td>612664</td>\n",
       "      <td>572756</td>\n",
       "      <td>806109</td>\n",
       "      <td>343719</td>\n",
       "      <td>160457</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>48</td>\n",
       "      <td>81</td>\n",
       "      <td>43</td>\n",
       "      <td>139872</td>\n",
       "      <td>76161</td>\n",
       "      <td>515730</td>\n",
       "      <td>2460</td>\n",
       "      <td>696074</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>64</td>\n",
       "      <td>71</td>\n",
       "      <td>34</td>\n",
       "      <td>1190577</td>\n",
       "      <td>628730</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1385 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age   Gender  BMI  Fever  Nausea/Vomting  Headache   Diarrhea   \\\n",
       "0       56       1   35      2               1          1          1   \n",
       "1       46       1   29      1               2          2          1   \n",
       "2       57       1   33      2               2          2          2   \n",
       "3       49       2   33      1               2          1          2   \n",
       "4       59       1   32      1               1          2          1   \n",
       "...    ...     ...  ...    ...             ...        ...        ...   \n",
       "1380    44       1   29      1               2          2          2   \n",
       "1381    55       1   34      1               2          2          1   \n",
       "1382    42       1   26      2               2          1          1   \n",
       "1383    52       1   29      2               1          1          2   \n",
       "1384    55       2   26      1               2          2          2   \n",
       "\n",
       "      Fatigue & generalized bone ache   Jaundice   Epigastric pain   ...  \\\n",
       "0                                    2          2                 2  ...   \n",
       "1                                    2          2                 1  ...   \n",
       "2                                    1          1                 1  ...   \n",
       "3                                    1          2                 1  ...   \n",
       "4                                    2          2                 2  ...   \n",
       "...                                ...        ...               ...  ...   \n",
       "1380                                 1          1                 1  ...   \n",
       "1381                                 1          1                 1  ...   \n",
       "1382                                 1          2                 1  ...   \n",
       "1383                                 2          2                 1  ...   \n",
       "1384                                 1          2                 1  ...   \n",
       "\n",
       "      ALT 36  ALT 48  ALT after 24 w  RNA Base   RNA 4   RNA 12  RNA EOT  \\\n",
       "0          5       5               5    655330  634536   288194        5   \n",
       "1         57     123              44     40620  538635   637056   336804   \n",
       "2          5       5               5    571148  661346        5   735945   \n",
       "3         48      77              33   1041941  449939   585688   744463   \n",
       "4         94      90              30    660410  738756  3731527   338946   \n",
       "...      ...     ...             ...       ...     ...      ...      ...   \n",
       "1380      63      44              45    387795   55938        5        5   \n",
       "1381      97      64              41    481378  152961   393339    73574   \n",
       "1382      87      39              24    612664  572756   806109   343719   \n",
       "1383      48      81              43    139872   76161   515730     2460   \n",
       "1384      64      71              34   1190577  628730        5        5   \n",
       "\n",
       "      RNA EF  Baseline histological Grading  Baselinehistological staging  \n",
       "0          5                             13                             2  \n",
       "1      31085                              4                             2  \n",
       "2     558829                              4                             4  \n",
       "3     582301                             10                             3  \n",
       "4     242861                             11                             1  \n",
       "...      ...                            ...                           ...  \n",
       "1380       5                             15                             4  \n",
       "1381  236273                             10                             2  \n",
       "1382  160457                              6                             2  \n",
       "1383  696074                             15                             3  \n",
       "1384       5                             13                             3  \n",
       "\n",
       "[1385 rows x 29 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"HCV-Egy-Data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(self, number_of_inputs,inputs):\n",
    "        self.number_of_inputs = number_of_inputs\n",
    "        self.weights = []\n",
    "        self.inputs = inputs\n",
    "        self.bias = random.uniform(-5, 5) \n",
    "        for i in range(number_of_inputs):\n",
    "            self.weights.append(random.uniform(-10, 10) )\n",
    "\n",
    "    def setInputs(self,inputs):\n",
    "        self.inputs = inputs\n",
    "        \n",
    "    def Z(self):\n",
    "        z = 0\n",
    "        for i in range(self.number_of_inputs):\n",
    "            z += self.weights[i] * self.inputs[i]\n",
    "        z += self.bias\n",
    "        return z\n",
    "    \n",
    "    def sigmoid(self):\n",
    "        return 1 / (1 + math.exp(-self.Z()))\n",
    "    \n",
    "    def differentiationOfSigmoid(self):\n",
    "        return self.sigmoid() * (1 - self.sigmoid())\n",
    "    \n",
    "    def differentiationOfZ(self,target): # w1674368   x468287  y4893804   w3   x5   y8\n",
    "        index = int(target[1:]) -1\n",
    "        if \"w\" in target.lower():\n",
    "            return self.inputs[index]\n",
    "        elif \"y\" in target.lower() or \"x\" in target.lower():\n",
    "            # Your code here\n",
    "            return self.weights[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(figsize=(40,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(28, 28))  # Adjust the width and height as needed\n",
    "\n",
    "sns.heatmap(df.corr(), cmap='Reds', annot=True, fmt='.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 29\n",
    "fig, axes = plt.subplots(nrows=num_features, ncols=1, figsize=(10, 5 * num_features))\n",
    "\n",
    "# Loop through each feature to create a PDF plot\n",
    "for i, column in enumerate(df):\n",
    "    # Plotting the density\n",
    "    df[column].plot(kind='density', ax=axes[i], color='blue', alpha=0.5, label='PDF')\n",
    "\n",
    "    # Calculate mean, median, and mode\n",
    "    mean = df[column].mean()\n",
    "    median = df[column].median()\n",
    "    mode = df[column].mode()[0]\n",
    "\n",
    "    # Marking mean, median, and mode with horizontal lines\n",
    "    axes[i].axvline(x=mean , color='red', linestyle='--', label=f'Mean: {mean:.2f}')  # Adjusted y-value for visibility\n",
    "    axes[i].axvline(x=median, color='green', linestyle='--', label=f'Median: {median:.2f}')  # Adjusted y-value for visibility\n",
    "    axes[i].axvline(x=mode , color='purple', linestyle='--', label=f'Mode: {mode:.2f}')  # Adjusted y-value for visibility\n",
    "\n",
    "    # Adding titles and labels\n",
    "    axes[i].set_title(f'Probability Density Function for {column}')\n",
    "    axes[i].set_xlabel(column)\n",
    "    axes[i].set_ylabel('Density')\n",
    "    axes[i].legend()\n",
    "    axes[i].grid()\n",
    "\n",
    "# Adjust layout and show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind='box', subplots=True, sharex=False, sharey=False, layout=(10,3), figsize=(15,25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = np.percentile(df['ALT after 24 w'], 25)\n",
    "Q3 = np.percentile(df['ALT after 24 w'], 75)\n",
    "IQR = Q3 - Q1\n",
    "df = df[(df['ALT after 24 w'] >= Q1 - 1.5 * IQR) & (df['ALT after 24 w'] <= Q3 + 1.5 * IQR)]\n",
    "\n",
    "Q1 = np.percentile(df['RNA 12'], 25)\n",
    "Q3 = np.percentile(df['RNA 12'], 75)\n",
    "IQR = Q3 - Q1\n",
    "df = df[(df['RNA 12'] >= Q1 - 1.5 * IQR) & (df['RNA 12'] <= Q3 + 1.5 * IQR)]\n",
    "\n",
    "df.plot(kind='box', subplots=True, sharex=False, sharey=False, layout=(10,3), figsize=(15,25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Update NN weights using Genetic Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_data = df.sample(frac=1)\n",
    "\"\"\"\n",
    "This script performs the following operations on a DataFrame `df`:\n",
    "\n",
    "1. Shuffles the DataFrame.\n",
    "2. Splits the DataFrame into features (X) and target (Y).\n",
    "3. Splits the data into training and testing sets with a 70-30 split.\n",
    "4. Further splits the testing set into validation and final test sets with a 2/3-1/3 split.\n",
    "\n",
    "Variables:\n",
    "    shuffled_data (DataFrame): The shuffled DataFrame.\n",
    "    X (ndarray): Feature matrix.\n",
    "    Y (ndarray): Target vector.\n",
    "    X_train (ndarray): Training feature matrix.\n",
    "    m_test (ndarray): Intermediate test feature matrix.\n",
    "    Y_train (ndarray): Training target vector.\n",
    "    my_test (ndarray): Intermediate test target vector.\n",
    "    X_validate (ndarray): Validation feature matrix.\n",
    "    X_test (ndarray): Final test feature matrix.\n",
    "    Y_validate (ndarray): Validation target vector.\n",
    "    Y_test (ndarray): Final test target vector.\n",
    "\"\"\"\n",
    "\n",
    "X = df.iloc[:,:-1].values\n",
    "Y = df.iloc[:,-1].values\n",
    "\n",
    "X_train, m_test, Y_train, my_test = train_test_split(X, Y, test_size = 0.30, random_state = 0)\n",
    "\n",
    "X_validate, X_test, Y_validate, Y_test = train_test_split(m_test, my_test, test_size = 1/3, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "  return 1 / (1 + np.exp(-x))\n",
    "\n",
    "sigs = np.vectorize(sigmoid)\n",
    "\n",
    "def targetToVector(target):\n",
    "   \"\"\"\n",
    "   Converts a target integer into a one-hot encoded vector of length 4.\n",
    "\n",
    "   Args:\n",
    "      target (int): The target integer, expected to be in the range 1 to 4.\n",
    "\n",
    "   Returns:\n",
    "      list: A one-hot encoded list of length 4, where the position corresponding \n",
    "         to the target integer is set to 1, and all other positions are set to 0.\n",
    "\n",
    "   Example:\n",
    "      >>> targetToVector(3)\n",
    "      [0, 0, 1, 0]\n",
    "   \"\"\"\n",
    "   return [1 if i+1 == target else 0 for i in range(4)]\n",
    "\n",
    "def fitness(predictedVector, targetVector):\n",
    "   \"\"\"\n",
    "   Calculate the fitness score by computing the sum of absolute differences \n",
    "   between the predicted vector and the target vector.\n",
    "\n",
    "   Args:\n",
    "      predictedVector (list of float): The predicted values.\n",
    "      targetVector (list of float): The actual target values.\n",
    "\n",
    "   Returns:\n",
    "      float: The fitness score, which is the sum of absolute differences \n",
    "      between the predicted and target vectors.\n",
    "   \"\"\"\n",
    "   return sum([abs(targetVector[i] - predictedVector[i]) for i in range(len(predictedVector))])\n",
    "\n",
    "\n",
    "def randomPopulation(size=500):\n",
    "   \"\"\"\n",
    "   Generates a random population of neural network weights and biases.\n",
    "\n",
    "   Args:\n",
    "      size (int): The number of neural networks to generate. Default is 500.\n",
    "\n",
    "   Returns:\n",
    "      tuple: A tuple containing four elements:\n",
    "         - W1s (list of list of list of float): Weights for the first layer of each neural network.\n",
    "         - W2s (list of list of list of float): Weights for the second layer of each neural network.\n",
    "         - B1s (list of list of float): Biases for the first layer of each neural network.\n",
    "         - B2s (list of list of float): Biases for the second layer of each neural network.\n",
    "   \"\"\"\n",
    "   W1s = [[[random.uniform(-10, 10) for i in range(28)] for j in range(10)] for count in range(size)]\n",
    "   W2s = [[[random.uniform(-10, 10) for i in range(10)] for j in range(4)] for count in range(size)]\n",
    "   B1s = [[random.uniform(-5, 5) for i in range(10)] for count in range(size)]\n",
    "   B2s = [[random.uniform(-5, 5) for i in range(4)] for count in range(size)]\n",
    "   return W1s, W2s, B1s, B2s\n",
    "\n",
    "def crossoverWeights(rate, population):\n",
    "    \"\"\"\n",
    "   Perform crossover on a population of genetic algorithms.\n",
    "   This function takes a population of genetic algorithms and performs crossover \n",
    "   operations to produce a new population. The crossover operation combines the \n",
    "   weights of two parent genes to produce new offspring genes.\n",
    "   Args:\n",
    "      rate (float): The crossover rate, which determines the proportion of the \n",
    "                 population that will undergo crossover.\n",
    "      population (list): The population of genetic algorithms, where each \n",
    "                     individual is represented as a list of weight vectors.\n",
    "   Returns:\n",
    "      list: The new population after crossover, which includes both the crossed \n",
    "           individuals and the remaining individuals from the original population.\n",
    "   \"\"\"\n",
    "    tmp_pop = population.copy()\n",
    "    crossed_pop = []\n",
    "\n",
    "    def cross(g1, g2):\n",
    "        cp = random.randrange(0, len(g1))\n",
    "        tg1_1 = g1[:cp]\n",
    "        tg1_2 = g1[cp:]\n",
    "        tg2_1 = g2[:cp]\n",
    "        tg2_2 = g2[cp:]\n",
    "        return (tg1_1 + tg2_2, tg2_1 + tg1_2)\n",
    "    \n",
    "    for i in range(int(rate/2*len(population))):\n",
    "        parentGene1 = tmp_pop[random.randrange(0, len(tmp_pop))]\n",
    "        tmp_pop.remove(parentGene1)\n",
    "        parentGene2 = tmp_pop[random.randrange(0, len(tmp_pop))]\n",
    "        tmp_pop.remove(parentGene2)\n",
    "\n",
    "\n",
    "        idx1, idx2 = random.randrange(0, len(parentGene1[0])), random.randrange(0, len(parentGene1[0]))\n",
    "        parentWeightVector1 = parentGene1[0][idx1]\n",
    "        parentWeightVector2 = parentGene2[0][idx2]                           \n",
    "         \n",
    "        new_w1_p1, new_w1_p2 = cross(parentWeightVector1 , parentWeightVector2)\n",
    "\n",
    "        parentGene1[0][idx1] = new_w1_p1\n",
    "        parentGene2[0][idx2] = new_w1_p2\n",
    "\n",
    "        idx1, idx2 = random.randrange(0, len(parentGene1[1])), random.randrange(0, len(parentGene1[1]))\n",
    "\n",
    "        parentWeightVector1 = parentGene1[1][idx1]\n",
    "        parentWeightVector2 = parentGene2[1][idx2]                           \n",
    "         \n",
    "        new_w2_p1, new_w2_p2 = cross(parentWeightVector1 , parentWeightVector2)\n",
    "\n",
    "        parentGene1[1][idx1] = new_w2_p1\n",
    "        parentGene2[1][idx2] = new_w2_p2\n",
    "\n",
    "\n",
    "        #print(\"crossed: \", (new_w1_p1, new_w2_p1, parentGene1[2], parentGene1[3]))\n",
    "        crossed_pop.append(parentGene1)\n",
    "        crossed_pop.append(parentGene2)\n",
    "        #print(len(crossed_pop), len(tmp_pop), len(crossed_pop + tmp_pop))\n",
    "    return crossed_pop + tmp_pop\n",
    "\n",
    "def mutationWeights(rate, weightCount, population):\n",
    "   \"\"\"\n",
    "   Applies mutation to a population of neural network weights.\n",
    "   Parameters:\n",
    "   rate (float): The mutation rate, a value between 0 and 1, indicating the probability of mutation for each gene.\n",
    "   weightCount (int): The number of weights in each gene.\n",
    "   population (list): A list of genes, where each gene is a tuple containing two lists of weights.\n",
    "   Returns:\n",
    "   list: A new population with mutated weights based on the given mutation rate.\n",
    "   \"\"\"\n",
    "   newPop = population.copy()\n",
    "   limit = rate*(len(population))\n",
    "   for i, gene in enumerate(population):\n",
    "      #print(gene)\n",
    "      if (random.random() <= rate):\n",
    "         if (limit > 0):\n",
    "            limit -=1\n",
    "            for j in range(weightCount):\n",
    "              newG = gene\n",
    "              idx = random.randrange(0, len(gene[0]))\n",
    "              rndW = random.randrange(0, len(gene[0][idx]))\n",
    "              newG[0][idx][rndW] = random.uniform(-10, 10)\n",
    "              idx = random.randrange(0, len(gene[1]))\n",
    "              rndW = random.randrange(0, len(gene[1][idx]))\n",
    "              newG[1][idx][rndW] = random.uniform(-10, 10)\n",
    "              \n",
    "              newPop[i] = newG\n",
    "         else:\n",
    "            break \n",
    "         \n",
    "   return newPop\n",
    "\n",
    "def mutationBias(rate,  population):\n",
    "   def mutationBias(rate, population):\n",
    "      \"\"\"\n",
    "      Apply mutation bias to a given population of genes.\n",
    "      Parameters:\n",
    "      rate (float): The mutation rate, a value between 0 and 1, representing the probability of mutation for each gene.\n",
    "      population (list): A list of genes, where each gene is a list containing sublists that represent different parts of the gene.\n",
    "      Returns:\n",
    "      list: A new population list with mutations applied based on the given rate.\n",
    "      Notes:\n",
    "      - The function creates a copy of the population to avoid modifying the original population.\n",
    "      - The mutation is applied by randomly selecting indices in the gene sublists and assigning them new values within the range [-5, 5].\n",
    "      - The number of mutations is limited by the product of the mutation rate and the population size.\n",
    "      \"\"\"\n",
    "   newPop = population.copy()\n",
    "   limit = rate*(len(population))\n",
    "   for i, gene in enumerate(population):\n",
    "      if (random.random() <= rate):\n",
    "         if (limit > 0):\n",
    "            limit -=1\n",
    "            newG = gene\n",
    "            idx = random.randrange(0, len(gene[0]))\n",
    "            newG[2][idx] = random.uniform(-5, 5)\n",
    "            idx = random.randrange(0, len(gene[1]))\n",
    "            newG[3][idx] = random.uniform(-5, 5)\n",
    "         else:\n",
    "            break \n",
    "         \n",
    "   return newPop\n",
    "   \n",
    "def selection(rate, population, fitness):\n",
    "   \"\"\"\n",
    "   Selects a subset of the population based on their fitness scores.\n",
    "\n",
    "   This function sorts the population based on their fitness scores and selects the top half of the population.\n",
    "   If the population size is odd, it includes one additional individual from the top half.\n",
    "\n",
    "   Args:\n",
    "      rate (float): The selection rate (not used in the current implementation).\n",
    "      population (list): The list of individuals in the population.\n",
    "      fitness (list): The list of fitness scores corresponding to each individual in the population.\n",
    "\n",
    "   Returns:\n",
    "      list: A list containing the selected individuals from the population.\n",
    "   \"\"\"\n",
    "   #print(\"pop in select\", len(population))\n",
    "   full = list(map(lambda y: y[0], sorted([(population[i], fitness[i]) for i in range(len(population))], key = lambda x: x[1])))\n",
    "   #print(\"in select: \",len(full[:int(len(population)/2)] + (full[:int(len(population)/2)] if len(population) % 2 == 0 else full[int(len(population)/2):])))\n",
    "   #print(len(full[:int(len(population)/2)]), len(full[:int(len(population)/2)] if len(population) % 2 == 0 else full[int(len(population)/2):]), len(full[:int(len(population)/2)] + (full[:int(len(population)/2)] if len(population) % 2 == 0 else full[:int(len(population)/2)+1])))\n",
    "   return full[:int(len(population)/2)] + (full[:int(len(population)/2)] if len(population) % 2 == 0 else full[:int(len(population)/2)+1])\n",
    "\n",
    "def genPopulationTuples(W1s, W2s, B1s, B2s):\n",
    "   \"\"\"\n",
    "   Generates a population of tuples from the given lists of weights and biases.\n",
    "   This function takes four lists of weights and biases, and generates a list of \n",
    "   tuples where each tuple is a combination of one element from each list.\n",
    "   Parameters:\n",
    "   W1s (list): A list of weights for the first layer.\n",
    "   W2s (list): A list of weights for the second layer.\n",
    "   B1s (list): A list of biases for the first layer.\n",
    "   B2s (list): A list of biases for the second layer.\n",
    "   Returns:\n",
    "   list: A list of tuples, where each tuple contains one weight from W1s, one weight \n",
    "        from W2s, one bias from B1s, and one bias from B2s.\n",
    "   \"\"\"\n",
    "   tuplePopulation = []\n",
    "\n",
    "   for w1 in W1s:\n",
    "      for w2 in W2s:\n",
    "         for b1 in B1s:\n",
    "            for b2 in B2s:  \n",
    "               tuplePopulation.append((w1, w2, b1, b2))\n",
    "\n",
    "   return tuplePopulation\n",
    "\n",
    "def forwardPass(population, dataPoint, target, fitness_results):\n",
    "   \"\"\"\n",
    "   Perform a forward pass through a population of neural networks and update their fitness scores.\n",
    "   Args:\n",
    "      population (list of tuples): Each tuple contains weights and biases for a neural network.\n",
    "                             Format: [(w1, w2, b1, b2), ...]\n",
    "      dataPoint (numpy array): Input data point to be fed into the neural networks.\n",
    "      target (int or float): The target value for the given data point.\n",
    "      fitness_results (list of floats): List to store the fitness scores of the neural networks.\n",
    "   Returns:\n",
    "      None: The function updates the fitness_results list in place.\n",
    "   \"\"\"\n",
    "   idx = 0\n",
    "\n",
    "   tuplePopulation = []\n",
    "\n",
    "   for w1, w2, b1, b2 in population :   # (w1,w2,b1,b2)\n",
    "      midResult = np.dot(w1, dataPoint)\n",
    "      actv_midResult = sigs(midResult + b1)\n",
    "               \n",
    "      finalResult = np.dot(w2, actv_midResult)\n",
    "      actv_finalResult = sigs(finalResult + b2)\n",
    "      #print(actv_finalResult)\n",
    "      fitness_results[idx] += fitness(actv_finalResult, targetToVector(target))\n",
    "      idx+=1\n",
    "\n",
    "def calculateErrorOf1Input(predictedVector, targetVector):  # 1/2 * sum(target - predicted)^2\n",
    "   error = 0\n",
    "   for i in range(len(targetVector)):\n",
    "      error += (targetVector[i]-predictedVector[i])**2   # target : [0, 0, 1, 0]   predicted: [0.1, 0.2, 0.7, 0]\n",
    "   return error * 0.5\n",
    "\n",
    "def train(data , expectedOutput , hiddenLayer, outputLayer):\n",
    "      hiddenLayerOutputs = []\n",
    "      outputLayerOutputs = []\n",
    "      hotY = targetToVector(expectedOutput)\n",
    "      for neuron in hiddenLayer:\n",
    "         neuron.setInputs(data)\n",
    "         hiddenLayerOutputs.append(neuron.sigmoid())\n",
    "      for i in range(len(outputLayer)):\n",
    "         outputLayer[i].setInputs(hiddenLayerOutputs)\n",
    "         outputLayerOutputs.append(outputLayer[i].sigmoid())\n",
    "      return calculateErrorOf1Input(outputLayerOutputs, hotY) , hiddenLayerOutputs, outputLayerOutputs\n",
    "      \n",
    "\n",
    "      \n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "def test_AymanAndOmarNour(labeled_input_matrix, weights_matrix):\n",
    "   \"\"\"\n",
    "   Tests the neural network with the given labeled input matrix and weights matrix.\n",
    "   Args:\n",
    "      labeled_input_matrix (list of lists): A matrix where each row represents a labeled input.\n",
    "         The first element of each row is the input vector, and the second element is the target output.\n",
    "      weights_matrix (list of numpy arrays): A list containing the weight matrices for the neural network.\n",
    "         weights_matrix[0] is the weight matrix for the input to hidden layer,\n",
    "         weights_matrix[1] is the weight matrix for the hidden to output layer,\n",
    "         weights_matrix[2] is the bias vector for the hidden layer,\n",
    "         weights_matrix[3] is the bias vector for the output layer.\n",
    "   Returns:\n",
    "      tuple: A tuple containing:\n",
    "         - Error_Vector (list): A list of error values for each input in the labeled input matrix.\n",
    "         - Error (float): The total error for all inputs in the labeled input matrix.\n",
    "   \"\"\"\n",
    "   idx = 0\n",
    "\n",
    "   x = labeled_input_matrix[0]\n",
    "   y = labeled_input_matrix[1]\n",
    "\n",
    "   Error_Vector = [0] * len(y)\n",
    "   Error = 0\n",
    "\n",
    "   for i in range(len(y)):\n",
    "      #print(len(lblEd))\n",
    "      yV = targetToVector(y[i])\n",
    "      \n",
    "      midResult = np.dot(weights_matrix[0], x[i])\n",
    "      actv_midResult = sigs(midResult + weights_matrix[2])\n",
    "               \n",
    "      finalResult = np.dot(weights_matrix[1], actv_midResult)\n",
    "      actv_finalResult = sigs(finalResult + weights_matrix[3])\n",
    "      Error_Vector[idx] = fitness(actv_finalResult, yV)\n",
    "      Error += fitness(actv_finalResult, yV)\n",
    "      idx += 1 \n",
    "\n",
    "   return Error_Vector, Error\n",
    "\n",
    "def error_AymanAndOmarNour(Actual_Outputs_Vector, Target_Output_Vector):\n",
    "   \"\"\"\n",
    "   Calculate the absolute error between actual outputs and target outputs.\n",
    "   Args:\n",
    "      Actual_Outputs_Vector (list): A list of actual output values.\n",
    "      Target_Output_Vector (list): A list of target output values.\n",
    "   Returns:\n",
    "      tuple: A tuple containing:\n",
    "         - Error_Vector (list): A list of absolute errors for each corresponding element.\n",
    "         - Error (float): The sum of all absolute errors.\n",
    "   \"\"\"\n",
    "   Error_Vector = [abs(Actual_Outputs_Vector[i] - Target_Output_Vector[i]) for i in range(len(Target_Output_Vector))]\n",
    "   Error = sum(Error_Vector)\n",
    "\n",
    "   return Error_Vector, Error\n",
    "      \n",
    "def create_layer(numberOfNeurons, numberOfInputs):\n",
    "    layer = []\n",
    "    for i in range(numberOfNeurons):\n",
    "        layer.append(Neuron(numberOfInputs,[]))\n",
    "    return layer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiddenLayer = create_layer(10, 28)\n",
    "outputLayer = create_layer(4, 10)\n",
    "learningRate = 0.1\n",
    "\n",
    "exitCondition = False\n",
    "counter = 0\n",
    "while (counter < 10):\n",
    "    counter += 1\n",
    "    np.random.shuffle(X_train)\n",
    "    batches = [                         [                            (X_train[bf * 69 + i], Y_train[bf * 69 + i]) for i in range(69)                        ] for bf in range(14)             ]\n",
    "\n",
    "    number_of_batches = len(batches)\n",
    "\n",
    "    for batch in batches: \n",
    "        error = 0\n",
    "        for dataPoint in batch:\n",
    "           singleError , hiddenLayerOutputs, outputLayerOutputs = train(dataPoint[0], dataPoint[1], hiddenLayer, outputLayer)\n",
    "           error += singleError  \n",
    "        # after finishing the batch\n",
    "        # diff output * y/z  * z/w\n",
    "        for i in range(len(outputLayer)): # back propagation for output layer\n",
    "            diffOfError = - (dataPoint[1] - outputLayerOutputs[i])\n",
    "            diffOfSigmoid = outputLayer[i].differentiationOfSigmoid()\n",
    "            for j in range(len(outputLayer[i].weights)):\n",
    "                diffOfZ = outputLayer[i].differentiationOfZ(f\"w{j+1}\")\n",
    "                deltaW = diffOfError * diffOfSigmoid * diffOfZ\n",
    "                outputLayer[i].weights[j] -= learningRate * deltaW\n",
    "\n",
    "        for i in range(len(outputLayer)): # back propagation for hidden layer\n",
    "            diffOfError = - (dataPoint[1] - outputLayerOutputs[i])\n",
    "            diffOfSigmoid = outputLayer[i].differentiationOfSigmoid()\n",
    "            for j in range(len(outputLayer[i].weights)):\n",
    "                diffOfZ = outputLayer[i].differentiationOfZ(f\"y{j+1}\")\n",
    "                for k in range(len(hiddenLayer)):\n",
    "                    diffOf2ndSigmoid = hiddenLayer[k].differentiationOfSigmoid()\n",
    "                    for l in range(len(hiddenLayer[k].weights)):\n",
    "                        diffOfInput = hiddenLayer[k].differentiationOfZ(f\"x{l+1}\")\n",
    "                        deltaW = diffOfError * diffOfSigmoid * diffOfZ  * diffOf2ndSigmoid * diffOfInput\n",
    "                        hiddenLayer[k].weights[l] -= learningRate * deltaW\n",
    "                \n",
    "\n",
    "        \n",
    "#     errVec, errAgg = test_AymanAndOmarNour((X_validate, Y_validate), bestGene[0])\n",
    "#     print(\"Epoch total error: \", errAgg)\n",
    " \n",
    "# print(\"===================================================\")\n",
    "\n",
    "# # code for testing\n",
    "# errVec, errAgg = test_AymanAndOmarNour((X_test, Y_test), bestGene[0])\n",
    "# test_std_dev = np.std(errVec)\n",
    "# print(f\"Test total error: {errAgg}, Accuracy: {100 - (errAgg/(len(Y_test)*4))*100}, Std Dev: {test_std_dev}\")\n",
    "\n",
    "# # code for validation\n",
    "# errVec, errAgg = test_AymanAndOmarNour((X_validate, Y_validate), bestGene[0])\n",
    "# validate_std_dev = np.std(errVec)\n",
    "# print(f\"Validate total error: {errAgg}, Accuracy: {100 - (errAgg/(len(Y_validate)*4))*100}, Std Dev: {validate_std_dev}\")\n",
    "\n",
    "# # code for training\n",
    "# errVec, errAgg = test_AymanAndOmarNour((X_train, Y_train), bestGene[0])\n",
    "# train_std_dev = np.std(errVec)\n",
    "# print(f\"Train total error: {errAgg}, Accuracy: {100 - (errAgg/(len(Y_train)*4))*100}, Std Dev: {train_std_dev}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
